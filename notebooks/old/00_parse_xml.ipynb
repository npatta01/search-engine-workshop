{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a60f42-da79-430e-961b-317edc336d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6caf469f-2e8a-40cc-8b91-781800e98486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts.xml  df_raw  df_raw.parquet  stackoverflow.com-Posts.7z  start.sh\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acd0842-dfbf-47e8-9351-bfe02d0d2682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mxpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnamespaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0melems_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattrs_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstylesheet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mmodin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Read XML document into a ``DataFrame`` object.\n",
       "\n",
       ".. versionadded:: 1.3.0\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "path_or_buffer : str, path object, or file-like object\n",
       "    Any valid XML string or path is acceptable. The string could be a URL.\n",
       "    Valid URL schemes include http, ftp, s3, and file.\n",
       "\n",
       "xpath : str, optional, default './\\*'\n",
       "    The XPath to parse required set of nodes for migration to DataFrame.\n",
       "    XPath should return a collection of elements and not a single\n",
       "    element. Note: The ``etree`` parser supports limited XPath\n",
       "    expressions. For more complex XPath, use ``lxml`` which requires\n",
       "    installation.\n",
       "\n",
       "namespaces : dict, optional\n",
       "    The namespaces defined in XML document as dicts with key being\n",
       "    namespace prefix and value the URI. There is no need to include all\n",
       "    namespaces in XML, only the ones used in ``xpath`` expression.\n",
       "    Note: if XML document uses default namespace denoted as\n",
       "    `xmlns='<URI>'` without a prefix, you must assign any temporary\n",
       "    namespace prefix such as 'doc' to the URI in order to parse\n",
       "    underlying nodes and/or attributes. For example, ::\n",
       "\n",
       "        namespaces = {\"doc\": \"https://example.com\"}\n",
       "\n",
       "elems_only : bool, optional, default False\n",
       "    Parse only the child elements at the specified ``xpath``. By default,\n",
       "    all child elements and non-empty text nodes are returned.\n",
       "\n",
       "attrs_only :  bool, optional, default False\n",
       "    Parse only the attributes at the specified ``xpath``.\n",
       "    By default, all attributes are returned.\n",
       "\n",
       "names :  list-like, optional\n",
       "    Column names for DataFrame of parsed XML data. Use this parameter to\n",
       "    rename original element names and distinguish same named elements.\n",
       "\n",
       "encoding : str, optional, default 'utf-8'\n",
       "    Encoding of XML document.\n",
       "\n",
       "parser : {'lxml','etree'}, default 'lxml'\n",
       "    Parser module to use for retrieval of data. Only 'lxml' and\n",
       "    'etree' are supported. With 'lxml' more complex XPath searches\n",
       "    and ability to use XSLT stylesheet are supported.\n",
       "\n",
       "stylesheet : str, path object or file-like object\n",
       "    A URL, file-like object, or a raw string containing an XSLT script.\n",
       "    This stylesheet should flatten complex, deeply nested XML documents\n",
       "    for easier parsing. To use this feature you must have ``lxml`` module\n",
       "    installed and specify 'lxml' as ``parser``. The ``xpath`` must\n",
       "    reference nodes of transformed XML document generated after XSLT\n",
       "    transformation and not the original XML document. Only XSLT 1.0\n",
       "    scripts and not later versions is currently supported.\n",
       "\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer', then use\n",
       "    gzip, bz2, zip or xz if path_or_buffer is a string ending in\n",
       "    '.gz', '.bz2', '.zip', or 'xz', respectively, and no decompression\n",
       "    otherwise. If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
       "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
       "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
       "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "df\n",
       "    A DataFrame.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "read_json : Convert a JSON string to pandas object.\n",
       "read_html : Read HTML tables into a list of DataFrame objects.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This method is best designed to import shallow XML documents in\n",
       "following format which is the ideal fit for the two-dimensions of a\n",
       "``DataFrame`` (row by column). ::\n",
       "\n",
       "        <root>\n",
       "            <row>\n",
       "              <column1>data</column1>\n",
       "              <column2>data</column2>\n",
       "              <column3>data</column3>\n",
       "              ...\n",
       "           </row>\n",
       "           <row>\n",
       "              ...\n",
       "           </row>\n",
       "           ...\n",
       "        </root>\n",
       "\n",
       "As a file format, XML documents can be designed any way including\n",
       "layout of elements and attributes as long as it conforms to W3C\n",
       "specifications. Therefore, this method is a convenience handler for\n",
       "a specific flatter design and not all possible XML structures.\n",
       "\n",
       "However, for more complex XML documents, ``stylesheet`` allows you to\n",
       "temporarily redesign original document with XSLT (a special purpose\n",
       "language) for a flatter version for migration to a DataFrame.\n",
       "\n",
       "This function will *always* return a single :class:`DataFrame` or raise\n",
       "exceptions due to issues with XML document, ``xpath``, or other\n",
       "parameters.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> xml = '''<?xml version='1.0' encoding='utf-8'?>\n",
       "... <data xmlns=\"http://example.com\">\n",
       "...  <row>\n",
       "...    <shape>square</shape>\n",
       "...    <degrees>360</degrees>\n",
       "...    <sides>4.0</sides>\n",
       "...  </row>\n",
       "...  <row>\n",
       "...    <shape>circle</shape>\n",
       "...    <degrees>360</degrees>\n",
       "...    <sides/>\n",
       "...  </row>\n",
       "...  <row>\n",
       "...    <shape>triangle</shape>\n",
       "...    <degrees>180</degrees>\n",
       "...    <sides>3.0</sides>\n",
       "...  </row>\n",
       "... </data>'''\n",
       "\n",
       ">>> df = pd.read_xml(xml)\n",
       ">>> df\n",
       "      shape  degrees  sides\n",
       "0    square      360    4.0\n",
       "1    circle      360    NaN\n",
       "2  triangle      180    3.0\n",
       "\n",
       ">>> xml = '''<?xml version='1.0' encoding='utf-8'?>\n",
       "... <data>\n",
       "...   <row shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\n",
       "...   <row shape=\"circle\" degrees=\"360\"/>\n",
       "...   <row shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\n",
       "... </data>'''\n",
       "\n",
       ">>> df = pd.read_xml(xml, xpath=\".//row\")\n",
       ">>> df\n",
       "      shape  degrees  sides\n",
       "0    square      360    4.0\n",
       "1    circle      360    NaN\n",
       "2  triangle      180    3.0\n",
       "\n",
       ">>> xml = '''<?xml version='1.0' encoding='utf-8'?>\n",
       "... <doc:data xmlns:doc=\"https://example.com\">\n",
       "...   <doc:row>\n",
       "...     <doc:shape>square</doc:shape>\n",
       "...     <doc:degrees>360</doc:degrees>\n",
       "...     <doc:sides>4.0</doc:sides>\n",
       "...   </doc:row>\n",
       "...   <doc:row>\n",
       "...     <doc:shape>circle</doc:shape>\n",
       "...     <doc:degrees>360</doc:degrees>\n",
       "...     <doc:sides/>\n",
       "...   </doc:row>\n",
       "...   <doc:row>\n",
       "...     <doc:shape>triangle</doc:shape>\n",
       "...     <doc:degrees>180</doc:degrees>\n",
       "...     <doc:sides>3.0</doc:sides>\n",
       "...   </doc:row>\n",
       "... </doc:data>'''\n",
       "\n",
       ">>> df = pd.read_xml(xml,\n",
       "...                  xpath=\"//doc:row\",\n",
       "...                  namespaces={\"doc\": \"https://example.com\"})\n",
       ">>> df\n",
       "      shape  degrees  sides\n",
       "0    square      360    4.0\n",
       "1    circle      360    NaN\n",
       "2  triangle      180    3.0\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/envs/stackoverflow/lib/python3.7/site-packages/modin/pandas/io.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.read_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f79a2-2d4a-4e88-896c-4f1e6ef2da80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: read_xml defaulting to pandas implementation.\n",
      "To request implementation, send an email to feature_requests@modin.org.\n",
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_xml(\"../data/Posts.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43983b-a874-4a2d-ab88-3ee25a468c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d8142-ba74-4ae4-9936-1056f4f8757b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "stackoverflow",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python (stackoverflow)",
   "language": "python",
   "name": "stackoverflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
